{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2025 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "\n",
        "(EDITED BY JOHN and Guwei)\n",
        "\n",
        "## Group Members\n",
        "- John Kim (1079731)\n",
        "- Guwei Ke\n",
        "\n",
        "## Overview\n",
        "\n",
        "This notebook contains codes to run the climate claim classification model.\n",
        "\n",
        "## Usage\n",
        "\n",
        "To run the model, please follow the steps below:\n",
        "1. Install jupyter notebook, if you haven't already. You can either use docker or install it directly on your machine. You can even use Google Colab to run the notebook.\n",
        "2. We have pip requirements in the block below, so you can run the whole notebook to install the required packages.\n",
        "3. Datasets will be automatically downloaded when you run the notebook. The dataset is quite large, so it may take some time to download."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_M4xfue2BDU",
        "outputId": "6e28d8ed-7f1a-4c43-a82f-aeda6f557418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.66.1)\n",
            "Collecting torch>=1.11.0 (from sentence-transformers)\n",
            "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.3.1)\n",
            "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (1.11.3)\n",
            "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
            "  Downloading huggingface_hub-0.31.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: Pillow in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (10.1.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from sentence-transformers) (4.8.0)\n",
            "Collecting filelock (from huggingface-hub>=0.20.0->sentence-transformers)\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.9.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
            "Collecting typing_extensions>=4.5.0 (from sentence-transformers)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.2)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.6.4.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.4.2 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.6.85 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.3.0 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.3.0->torch>=1.11.0->sentence-transformers) (68.2.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.24.4)\n",
            "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
            "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2023.7.22)\n",
            "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.31.2-py3-none-any.whl (484 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m484.2/484.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: nvidia-cusparselt-cu12, typing_extensions, triton, sympy, safetensors, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, filelock, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, sentence-transformers\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.8.0\n",
            "    Uninstalling typing_extensions-4.8.0:\n",
            "      Successfully uninstalled typing_extensions-4.8.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.12\n",
            "    Uninstalling sympy-1.12:\n",
            "      Successfully uninstalled sympy-1.12\n",
            "Successfully installed filelock-3.18.0 huggingface-hub-0.31.2 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 regex-2024.11.6 safetensors-0.5.3 sentence-transformers-4.1.0 sympy-1.14.0 tokenizers-0.21.1 torch-2.7.0 transformers-4.51.3 triton-3.3.0 typing_extensions-4.13.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting numpy<3.0,>=1.25.0 (from faiss-cpu)\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m606.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from faiss-cpu) (23.2)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m676.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, faiss-cpu\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.2.5 which is incompatible.\n",
            "contourpy 1.1.1 requires numpy<2.0,>=1.16; python_version <= \"3.11\", but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 2.2.5 which is incompatible.\n",
            "scipy 1.11.3 requires numpy<1.28.0,>=1.21.6, but you have numpy 2.2.5 which is incompatible.\n",
            "scikit-learn 1.3.1 requires numpy<2.0,>=1.17.3, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed faiss-cpu-1.11.0 numpy-2.2.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from datasets) (2.2.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (from datasets) (2.1.1)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tqdm>=4.66.3 (from datasets)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2023.9.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.11/site-packages (from datasets) (0.31.2)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.8.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, tqdm, requests, pyarrow, dill, multiprocess, datasets\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 13.0.0\n",
            "    Uninstalling pyarrow-13.0.0:\n",
            "      Successfully uninstalled pyarrow-13.0.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.7\n",
            "    Uninstalling dill-0.3.7:\n",
            "      Successfully uninstalled dill-0.3.7\n",
            "Successfully installed datasets-3.6.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-20.0.0 requests-2.32.3 tqdm-4.67.1 xxhash-3.5.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting gdown\n",
            "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (from gdown) (4.12.2)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.11/site-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.11/site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: gdown\n",
            "Successfully installed gdown-5.2.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (2.7.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.31.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2023.9.2)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.2)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0.0->accelerate) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.3.0->torch>=2.0.0->accelerate) (68.2.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2023.7.22)\n",
            "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m497.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "Successfully installed accelerate-1.7.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: transformers[torch] in /opt/conda/lib/python3.11/site-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (0.31.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (2.2.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.0 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (2.7.0)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (1.7.0)\n",
            "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2023.9.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (1.14.0)\n",
            "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (3.2)\n",
            "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.0 in /opt/conda/lib/python3.11/site-packages (from torch>=2.0->transformers[torch]) (3.3.0)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.11/site-packages (from triton==3.3.0->torch>=2.0->transformers[torch]) (68.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: huggingface_hub[hf_xet] in /opt/conda/lib/python3.11/site-packages (0.31.2)\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_xet]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_xet]) (2023.9.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_xet]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_xet]) (6.0.1)\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_xet]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_xet]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.11/site-packages (from huggingface_hub[hf_xet]) (4.13.2)\n",
            "Collecting hf-xet<2.0.0,>=1.1.1 (from huggingface_hub[hf_xet])\n",
            "  Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub[hf_xet]) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub[hf_xet]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub[hf_xet]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface_hub[hf_xet]) (2023.7.22)\n",
            "Downloading hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hf-xet\n",
            "Successfully installed hf-xet-1.1.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: seaborn in /opt/conda/lib/python3.11/site-packages (0.13.0)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.11/site-packages (from seaborn) (2.2.5)\n",
            "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.11/site-packages (from seaborn) (2.1.1)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /opt/conda/lib/python3.11/site-packages (from seaborn) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
            "Collecting numpy!=1.24.0,>=1.20 (from seaborn)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m204.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.57.1 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.11/site-packages (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (10.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Below is a script to install the required packages for the project. (Similar to requirements.txt)\n",
        "\n",
        "%pip install sentence-transformers\n",
        "%pip install faiss-cpu\n",
        "%pip install faiss-gpu\n",
        "%pip install datasets\n",
        "%pip install gdown\n",
        "%pip install accelerate\n",
        "%pip install transformers[torch]\n",
        "%pip install huggingface_hub[hf_xet]\n",
        "%pip install seaborn\n",
        "%pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TL_m0QERE0YP"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "from sentence_transformers import CrossEncoder\n",
        "from sentence_transformers import InputExample, SentenceTransformer, losses\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import gdown\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oddPvCcS569j",
        "outputId": "850e780a-1547-414f-e00b-8ca0a7958fb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1SIlHpjPhgr5NJpf6nK79aCevoOmvZgML\n",
            "From (redirected): https://drive.google.com/uc?id=1SIlHpjPhgr5NJpf6nK79aCevoOmvZgML&confirm=t&uuid=b48f7059-8c52-42f7-a817-c92798458216\n",
            "To: /home/jovyan/evidence.json\n",
            "100%|██████████| 174M/174M [00:16<00:00, 10.9MB/s] \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aTH-Zzq9dztxxXIPDW8MY3HZR_6pGbSt\n",
            "To: /home/jovyan/dev-claims.json\n",
            "100%|██████████| 41.5k/41.5k [00:00<00:00, 356kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iliVuUhHp2M48Svxl2FUa4hWaOxnnTo7\n",
            "To: /home/jovyan/train-claims.json\n",
            "100%|██████████| 328k/328k [00:00<00:00, 1.03MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-AWc4xhd7YVV45tOti9Uu778x4YCsyeZ\n",
            "To: /home/jovyan/test-claims-unlabelled.json\n",
            "100%|██████████| 24.3k/24.3k [00:00<00:00, 502kB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zvWH6i6EQwTVgFlaKfNm6TXeo6DEEA9m\n",
            "To: /home/jovyan/dev-claims-baseline.json\n",
            "100%|██████████| 49.6k/49.6k [00:00<00:00, 382kB/s]\n"
          ]
        }
      ],
      "source": [
        "# This allows you to download files from Google Drive directly into your Colab environment. these files are stored in John's google drive.\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# # File Path\n",
        "# data_dir = \"/content/drive/MyDrive/COMP90042-Data\"\n",
        "\n",
        "\n",
        "# URLs of the files to download\n",
        "urls = [\n",
        "    \"https://drive.google.com/uc?id=1SIlHpjPhgr5NJpf6nK79aCevoOmvZgML\",\n",
        "    \"https://drive.google.com/uc?id=1aTH-Zzq9dztxxXIPDW8MY3HZR_6pGbSt\",\n",
        "    \"https://drive.google.com/uc?id=1iliVuUhHp2M48Svxl2FUa4hWaOxnnTo7\",\n",
        "    \"https://drive.google.com/uc?id=1-AWc4xhd7YVV45tOti9Uu778x4YCsyeZ\",\n",
        "    \"https://drive.google.com/uc?id=1zvWH6i6EQwTVgFlaKfNm6TXeo6DEEA9m\"\n",
        "]\n",
        "\n",
        "# Corresponding filenames\n",
        "filenames = [\n",
        "    \"evidence.json\",\n",
        "    \"dev-claims.json\",\n",
        "    \"train-claims.json\",\n",
        "    \"test-claims-unlabelled.json\",\n",
        "    \"dev-claims-baseline.json\"\n",
        "]\n",
        "\n",
        "# Download each file\n",
        "for url, filename in zip(urls, filenames):\n",
        "    if not os.path.exists(filename):\n",
        "        gdown.download(url, filename, quiet=False)\n",
        "    else:\n",
        "        print(f\"{filename} already exists. Skipping download.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RgZRiaYs1tnp"
      },
      "outputs": [],
      "source": [
        "def retrieve(evi_ebds, claim_ebds, evi_df, claim_df, retrival_top_k, rerank_top_k,threshold_activated,score_threshold, cross_encoder,dev):\n",
        "    embedding_dim = evi_ebds.shape[1]\n",
        "    index = faiss.IndexFlatL2(embedding_dim)\n",
        "    faiss.normalize_L2(evi_ebds)\n",
        "    index.add(evi_ebds)\n",
        "    retrieval = pd.DataFrame()\n",
        "    retrieved_labels = []\n",
        "    retrieved_evidences = []\n",
        "\n",
        "    i = 0\n",
        "    counts = 0\n",
        "    claim_texts = []\n",
        "    total = len(claim_ebds)\n",
        "    for dev_claim_embedding in claim_ebds:\n",
        "        faiss.normalize_L2(dev_claim_embedding.reshape(1, -1))\n",
        "        D, I = index.search(dev_claim_embedding.reshape(1, -1), retrival_top_k)\n",
        "        text = claim_df.iloc[i]['claim_text']\n",
        "        pairs = [(text, evi_df['value'][a]) for a in I[0]]\n",
        "        scores = cross_encoder.predict(pairs)\n",
        "        reranked = sorted(zip(I[0], scores), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        retrieved_evidence = []\n",
        "        filtered = []\n",
        "        first = True\n",
        "        for idx, score in reranked[:rerank_top_k]:\n",
        "            if first:\n",
        "                evi_id = evi_df['ID'][idx]\n",
        "                evi_content = evi_df['value'][idx]\n",
        "                retrieved_evidence.append(evi_id)\n",
        "                filtered.append((evi_id, score, evi_content))\n",
        "                first = False\n",
        "            else:\n",
        "                if not threshold_activated or score >= score_threshold:\n",
        "                    evi_id = evi_df['ID'][idx]\n",
        "                    evi_content = evi_df['value'][idx]\n",
        "                    retrieved_evidence.append(evi_id)\n",
        "                    filtered.append((evi_id, score, evi_content))\n",
        "\n",
        "        retrieved_evi =  [evi_df['ID'][a] for a in I[0]]\n",
        "        retrieved_evidences.append(retrieved_evidence)\n",
        "        retrieved_labels.append('SUPPORTS')\n",
        "        claim_texts.append(text)\n",
        "\n",
        "        if dev:\n",
        "            print(f\"Claim: {text}\")\n",
        "            if len(filtered) > 0:\n",
        "                print(\"evidence relevant\")\n",
        "                for eid, score, c in filtered:\n",
        "                    print(f\"  {eid}, Score: {score:.4f} \")\n",
        "            print(f\"Ground truth: {claim_df.iloc[i]['evidences']}\\n\")\n",
        "\n",
        "            count = 0\n",
        "            for g in claim_df.iloc[i]['evidences']:\n",
        "                if g in retrieved_evi:\n",
        "                    count += 1\n",
        "            counts += count / len(claim_df.iloc[i]['evidences'])\n",
        "\n",
        "        print('Progress ', round(i * 100 / total, 3), '%')\n",
        "        i += 1\n",
        "\n",
        "    print(\"R: \", counts/ i)\n",
        "\n",
        "    # Create the dataframe with all necessary information\n",
        "    retrieval['ID'] = claim_df['ID'].values[:len(retrieved_evidences)]\n",
        "    retrieval['evidences'] = retrieved_evidences\n",
        "    retrieval['claim_label'] = retrieved_labels\n",
        "    retrieval['claim_text'] = claim_texts\n",
        "\n",
        "    return retrieval\n",
        "\n",
        "def mine_hard_negatives(retrieved_evidences, ground_truth_evidences):\n",
        "    negative_evidences = []\n",
        "    for i in range(len(retrieved_evidences)):\n",
        "        retrieved_evidence = retrieved_evidences.iloc[i]\n",
        "        ground_truth_evidence = ground_truth_evidences.iloc[i]\n",
        "        negative_evidence = []\n",
        "        for e in retrieved_evidence:\n",
        "            if e not in ground_truth_evidence:\n",
        "                negative_evidence.append(int(re.findall(r'\\d+', e)[0]))\n",
        "        negative_evidences.append(negative_evidence)\n",
        "    return negative_evidences\n",
        "\n",
        "def load_train_data(train_dataframe, evidence_dateframe, random_negatives_amount_per_claim):\n",
        "    train_data = []\n",
        "    for id in range(len(train_dataframe)):\n",
        "        claim_text =  train_dataframe.iloc[id]['claim_text']\n",
        "        # print(\"CLAIM: \", claim_text)\n",
        "        positive_evidence_ids = train_dataframe.iloc[id]['evidences_numeric_index']\n",
        "        negative_evidence_ids = train_dataframe.iloc[id]['negative_evidences']\n",
        "        for evid_id in positive_evidence_ids:\n",
        "\n",
        "            evidence_text = evidence_dateframe.iloc[evid_id]['value']\n",
        "            # print(\"POSITIVE: \", evidence_text)\n",
        "            train_data.append(InputExample(texts=[claim_text, evidence_text], label=1.0))\n",
        "        for ngevid_id in negative_evidence_ids:\n",
        "            evidence_text = evidence_dateframe.iloc[ngevid_id]['value']\n",
        "            # print(\"NEGATIVE: \", evidence_text)\n",
        "            train_data.append(InputExample(texts=[claim_text, evidence_text], label=0.0))\n",
        "\n",
        "        for i in range(random_negatives_amount_per_claim):\n",
        "            neg_id = random.choice(list(set(evidence_dateframe.index) - set(positive_evidence_ids)))\n",
        "            neg_text = evidence_dateframe.iloc[neg_id]['value']\n",
        "            train_data.append(InputExample(texts=[claim_text, neg_text], label=0.0))\n",
        "    return train_data\n",
        "\n",
        "def load_positive_train_data(train_dataframe, evidence_dateframe):\n",
        "    train_data = []\n",
        "    for id in range(len(train_dataframe)):\n",
        "        claim_text =  train_dataframe.iloc[id]['claim_text']\n",
        "        positive_evidence_ids = train_dataframe.iloc[id]['evidences_numeric_index']\n",
        "        for evid_id in positive_evidence_ids:\n",
        "            evidence_text = evidence_dateframe.iloc[evid_id]['value']\n",
        "            train_data.append(InputExample(texts=[claim_text, evidence_text], label=1.0))\n",
        "    return train_data\n",
        "\n",
        "def save_retrieval(retrieval, path):\n",
        "    output = {}\n",
        "    for i in range(len(retrieval)):\n",
        "        output[retrieval.iloc[i]['ID']] = {}\n",
        "        output[retrieval.iloc[i]['ID']]['evidences'] = retrieval.iloc[i]['evidences']\n",
        "        output[retrieval.iloc[i]['ID']]['claim_label'] = retrieval.iloc[i]['claim_label']\n",
        "        output[retrieval.iloc[i]['ID']]['claim_text'] = retrieval.iloc[i]['claim_text']\n",
        "\n",
        "    with open(path, 'w') as file:\n",
        "        file.write(json.dumps(output))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SLYK-guqEbP"
      },
      "source": [
        "Read evidence dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hr4_3r4SrGtO",
        "outputId": "54d91484-194e-4f62-9c1e-945f24ea8f36"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>evidence-0</td>\n",
              "      <td>John Bennet Lawes, English entrepreneur and ag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>evidence-1</td>\n",
              "      <td>Lindberg began his professional career at the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>evidence-2</td>\n",
              "      <td>``Boston (Ladies of Cambridge)'' by Vampire We...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>evidence-3</td>\n",
              "      <td>Gerald Francis Goyer (born October 20, 1936) w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>evidence-4</td>\n",
              "      <td>He detected abnormalities of oxytocinergic fun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ID                                              value\n",
              "0  evidence-0  John Bennet Lawes, English entrepreneur and ag...\n",
              "1  evidence-1  Lindberg began his professional career at the ...\n",
              "2  evidence-2  ``Boston (Ladies of Cambridge)'' by Vampire We...\n",
              "3  evidence-3  Gerald Francis Goyer (born October 20, 1936) w...\n",
              "4  evidence-4  He detected abnormalities of oxytocinergic fun..."
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open('evidence.json', 'r') as f:\n",
        "    evidence = json.load(f)\n",
        "flat_list = []\n",
        "for key in evidence:\n",
        "    flat_list.append({\"ID\": key, \"value\": evidence[key]})\n",
        "\n",
        "evidence_df = pd.DataFrame(flat_list)\n",
        "\n",
        "evidence_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyV8f8Pa1tnt"
      },
      "source": [
        "Read training and developing datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "0NPsiZNX1tnt",
        "outputId": "70b9f247-92e5-4502-8139-38c472d474c8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_label</th>\n",
              "      <th>evidences</th>\n",
              "      <th>evidences_numeric_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>claim-1937</td>\n",
              "      <td>Not only is there no scientific evidence that ...</td>\n",
              "      <td>DISPUTED</td>\n",
              "      <td>[evidence-442946, evidence-1194317, evidence-1...</td>\n",
              "      <td>[442946, 1194317, 12171]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>claim-126</td>\n",
              "      <td>El Niño drove record highs in global temperatu...</td>\n",
              "      <td>REFUTES</td>\n",
              "      <td>[evidence-338219, evidence-1127398]</td>\n",
              "      <td>[338219, 1127398]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>claim-2510</td>\n",
              "      <td>In 1946, PDO switched to a cool phase.</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[evidence-530063, evidence-984887]</td>\n",
              "      <td>[530063, 984887]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>claim-2021</td>\n",
              "      <td>Weather Channel co-founder John Coleman provid...</td>\n",
              "      <td>DISPUTED</td>\n",
              "      <td>[evidence-1177431, evidence-782448, evidence-5...</td>\n",
              "      <td>[1177431, 782448, 540069, 352655, 1007867]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>claim-2449</td>\n",
              "      <td>\"January 2008 capped a 12 month period of glob...</td>\n",
              "      <td>NOT_ENOUGH_INFO</td>\n",
              "      <td>[evidence-1010750, evidence-91661, evidence-72...</td>\n",
              "      <td>[1010750, 91661, 722725, 554161, 430839]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ID                                         claim_text  \\\n",
              "0  claim-1937  Not only is there no scientific evidence that ...   \n",
              "1   claim-126  El Niño drove record highs in global temperatu...   \n",
              "2  claim-2510             In 1946, PDO switched to a cool phase.   \n",
              "3  claim-2021  Weather Channel co-founder John Coleman provid...   \n",
              "4  claim-2449  \"January 2008 capped a 12 month period of glob...   \n",
              "\n",
              "       claim_label                                          evidences  \\\n",
              "0         DISPUTED  [evidence-442946, evidence-1194317, evidence-1...   \n",
              "1          REFUTES                [evidence-338219, evidence-1127398]   \n",
              "2         SUPPORTS                 [evidence-530063, evidence-984887]   \n",
              "3         DISPUTED  [evidence-1177431, evidence-782448, evidence-5...   \n",
              "4  NOT_ENOUGH_INFO  [evidence-1010750, evidence-91661, evidence-72...   \n",
              "\n",
              "                      evidences_numeric_index  \n",
              "0                    [442946, 1194317, 12171]  \n",
              "1                           [338219, 1127398]  \n",
              "2                            [530063, 984887]  \n",
              "3  [1177431, 782448, 540069, 352655, 1007867]  \n",
              "4    [1010750, 91661, 722725, 554161, 430839]  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open('train-claims.json', 'r') as f:\n",
        "    train_df = json.load(f)\n",
        "flat_list = []\n",
        "for key in train_df:\n",
        "    evidences_numeric_index = []\n",
        "    for e in train_df[key]['evidences']:\n",
        "        evidences_numeric_index.append(int(re.findall(r'\\d+', e)[0]))\n",
        "    flat_list.append({\"ID\": key, \"claim_text\": train_df[key]['claim_text'], \"claim_label\": train_df[key]['claim_label'], \"evidences\": train_df[key]['evidences'], \"evidences_numeric_index\": evidences_numeric_index})\n",
        "train_df = pd.DataFrame(flat_list)\n",
        "\n",
        "train_df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "Xix_shVisan3",
        "outputId": "38c13110-726d-4e01-b412-5b8ca32f81f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>claim_text</th>\n",
              "      <th>claim_label</th>\n",
              "      <th>evidences</th>\n",
              "      <th>evidences_numeric_index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>claim-752</td>\n",
              "      <td>[South Australia] has the most expensive elect...</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[evidence-67732, evidence-572512]</td>\n",
              "      <td>[67732, 572512]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>claim-375</td>\n",
              "      <td>when 3 per cent of total annual global emissio...</td>\n",
              "      <td>NOT_ENOUGH_INFO</td>\n",
              "      <td>[evidence-996421, evidence-1080858, evidence-2...</td>\n",
              "      <td>[996421, 1080858, 208053, 699212, 832334]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>claim-1266</td>\n",
              "      <td>This means that the world is now 1C warmer tha...</td>\n",
              "      <td>SUPPORTS</td>\n",
              "      <td>[evidence-889933, evidence-694262]</td>\n",
              "      <td>[889933, 694262]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>claim-871</td>\n",
              "      <td>“As it happens, Zika may also be a good model ...</td>\n",
              "      <td>NOT_ENOUGH_INFO</td>\n",
              "      <td>[evidence-422399, evidence-702226, evidence-28...</td>\n",
              "      <td>[422399, 702226, 286834, 472751, 641043]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>claim-2164</td>\n",
              "      <td>Greenland has only lost a tiny fraction of its...</td>\n",
              "      <td>REFUTES</td>\n",
              "      <td>[evidence-52981, evidence-264761, evidence-947...</td>\n",
              "      <td>[52981, 264761, 947243, 424102]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           ID                                         claim_text  \\\n",
              "0   claim-752  [South Australia] has the most expensive elect...   \n",
              "1   claim-375  when 3 per cent of total annual global emissio...   \n",
              "2  claim-1266  This means that the world is now 1C warmer tha...   \n",
              "3   claim-871  “As it happens, Zika may also be a good model ...   \n",
              "4  claim-2164  Greenland has only lost a tiny fraction of its...   \n",
              "\n",
              "       claim_label                                          evidences  \\\n",
              "0         SUPPORTS                  [evidence-67732, evidence-572512]   \n",
              "1  NOT_ENOUGH_INFO  [evidence-996421, evidence-1080858, evidence-2...   \n",
              "2         SUPPORTS                 [evidence-889933, evidence-694262]   \n",
              "3  NOT_ENOUGH_INFO  [evidence-422399, evidence-702226, evidence-28...   \n",
              "4          REFUTES  [evidence-52981, evidence-264761, evidence-947...   \n",
              "\n",
              "                     evidences_numeric_index  \n",
              "0                            [67732, 572512]  \n",
              "1  [996421, 1080858, 208053, 699212, 832334]  \n",
              "2                           [889933, 694262]  \n",
              "3   [422399, 702226, 286834, 472751, 641043]  \n",
              "4            [52981, 264761, 947243, 424102]  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with open('dev-claims.json', 'r') as f:\n",
        "    dev_df = json.load(f)\n",
        "flat_list = []\n",
        "for key in dev_df:\n",
        "    evidences_numeric_index = []\n",
        "    for e in dev_df[key]['evidences']:\n",
        "        evidences_numeric_index.append(int(re.findall(r'\\d+', e)[0]))\n",
        "    flat_list.append({\"ID\": key, \"claim_text\": dev_df[key]['claim_text'], \"claim_label\": dev_df[key]['claim_label'], \"evidences\": dev_df[key]['evidences'], \"evidences_numeric_index\": evidences_numeric_index})\n",
        "dev_df = pd.DataFrame(flat_list)\n",
        "\n",
        "dev_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdxzOWLn1tnu"
      },
      "source": [
        "Calculate sentence embeddings for evidence dataset and trainning dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529,
          "referenced_widgets": [
            "087ee78e4ed24bc4b6d1580cd62afc35",
            "a8d985dcf88045ad89b879e8464dea64",
            "e7d5fdfbb44f42f3a911d38566cce564",
            "a78dfc05f8804769800944f737043be8",
            "dd44a5a86c064e3095eba251ef7cb407",
            "f07f0f107da84d07bc344b1429bacc46",
            "cb98c824d58e4cacbad2f178e8ad6047",
            "c0e3508ba161497f9a625f3408c8c001",
            "3efa77c5f3364325a7a86a3d0043dd74",
            "369bb264d861472686414d13b6d55fe2",
            "0c09a86b14ad45418907647f1eae9b85",
            "13a1ee388bf643ed8204c2c3b0466246",
            "9d91ef6c522c4845bc21e2fd2a0c5df3",
            "0ae1257979604bb69d292bc3334fd7df",
            "315e3f11482c47deb9a4288a1998305f",
            "4f45b82f78094b40a393fe063095ae64",
            "73b44ac385674c04a8b753ad5601689c",
            "23aa8d93e507418eb7600766bf0130ef",
            "86c58567b73f4d21b07bd867f1a74a95",
            "361a897e3ee843bf880a9a96075be79c",
            "65949cecb87b49528da679d87bd263ea",
            "df8c4abec5a44cdd8b994948c59769c5",
            "fb1918ee12f144aaa7b9ec549e044d3d",
            "b655a47931314ea2bb9e7bbf001c8a65",
            "d0dde043112745159cd59c4fe5557b66",
            "9349372512dd4bfd84e5a8673a5bf38f",
            "080e9631ab6e4af4812b00b33e514a73",
            "6baee30c35834de6a41595b48ca650df",
            "dc07fc4b3ff34d1fba0dfa050faa1dab",
            "9109e87ea86a477db3c6a077325ba5f8",
            "68ef3582c85144ca901fe0721f771681",
            "6dfa3cba90f642a582e737ba33fd6b0c",
            "955aa777810b44d6a372a27053d2a842",
            "b4a57a56ca22406781400f42b4aca6d5",
            "d9189a6818b744679c5f6dfe2cdfa6eb",
            "bb6d9ba5d27947909d7e467e9a7617a9",
            "39fc652c065c41eb881000a82cdba552",
            "a584fdcdf1864079a52ee22b4937c67c",
            "40264050651b4732bcbd198e77e90139",
            "2e23e1bfe71043bf9b9b5838a79c6b86",
            "5c9d88e0ad164283bb6c2f426a9567a0",
            "672e1e25795d4222a01ef2c06efe982d",
            "885e10fe23b34691bd5de4e98d5aae8a",
            "db323d362eb246e5a6049af3eea628eb"
          ]
        },
        "id": "QIEqDDT78q39",
        "outputId": "a1b4613f-587f-4a7f-dac2-3bfe26cdf052"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fab5140234fc4ae59ae75081ee5b601f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ae6882f30f14e5491ca9692cd09db9a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31bfdd7901894a538395dab2ec55299c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c17ebefcebc4dc6b91cc5a1f6db1351",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b392d902ca5d4ff084c27e4e38feaa5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ba8f22bbbddf467482986edd68bf718f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "867edcc3572e441683420e2cb7e39ea3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe44fd38673649d08f51e76b8552d53e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89d78067337b4139b7536ae48e423306",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "abda2865b6094ffe927902a13738d313",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fb95c7024df47f78602af2be9eda877",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3cace638d29143b280bd60f1c4c3ea0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='774' max='774' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [774/774 11:27, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.895500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e458ed23e184a9e8bbe41d83971e093",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/18888 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26f003143ce849a896ea09ecea2d5be9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35b173e49d8e40318347020563373f90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
        "\n",
        "train_data = load_positive_train_data(train_df, evidence_df)\n",
        "train_dataloader = DataLoader(train_data, shuffle=True, batch_size=16)\n",
        "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
        "\n",
        "model.fit(\n",
        "    train_objectives=[(train_dataloader, train_loss)],\n",
        "    epochs=3,\n",
        "    output_path='./output-bi-encoder',\n",
        "    weight_decay=0.01\n",
        ")\n",
        "\n",
        "evidence_embeddings = model.encode(evidence_df['value'], batch_size=64, show_progress_bar=True)\n",
        "dev_claims_embeddings = model.encode(dev_df['claim_text'], batch_size=64, show_progress_bar=True)\n",
        "train_claims_embeddings = model.encode(train_df['claim_text'], batch_size=64, show_progress_bar=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK9XRpJs1tnu"
      },
      "source": [
        "Fine tune cross encoder for re-ranking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxvUMWz_1tnu",
        "outputId": "87ad25e9-79c9-4f70-d30d-93dd62e5118e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4122\n"
          ]
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "def load_positive_train_ds(train_dataframe, evidence_dateframe, t_ebds, e_ebds):\n",
        "    query = []\n",
        "    answer = []\n",
        "    for id in range(len(train_dataframe)):\n",
        "        claim_text =  train_dataframe.iloc[id]['claim_text']\n",
        "        positive_evidence_ids = train_dataframe.iloc[id]['evidences_numeric_index']\n",
        "        # claim_ebd = t_ebds[id]\n",
        "        # none_added = True\n",
        "        for evid_id in positive_evidence_ids:\n",
        "\n",
        "            # evi_ebd = e_ebds[evid_id]\n",
        "            evidence = evidence_dateframe.iloc[evid_id]['value']\n",
        "            # similarities = model.similarity(claim_ebd, evi_ebd)\n",
        "\n",
        "            # if similarities > 0:\n",
        "            #     none_added = False\n",
        "            # print('Claim: ', claim_text)\n",
        "            # print('Evidence: ', evidence)\n",
        "\n",
        "            query.append(claim_text)\n",
        "            answer.append(evidence)\n",
        "        # if none_added:\n",
        "        #     query.append(claim_text)\n",
        "        #     answer.append(evidence_dateframe.iloc[positive_evidence_ids[0]]['value'])\n",
        "\n",
        "    return Dataset.from_dict({\n",
        "    \"query\": query,\n",
        "    \"answer\": answer,})\n",
        "\n",
        "\n",
        "train_dataset = load_positive_train_ds(train_df, evidence_df, train_claims_embeddings, evidence_embeddings)\n",
        "print(len(train_dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCVCGD7kE0YR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337,
          "referenced_widgets": [
            "2827540ce35c47ff8d1e2eb3712b550e",
            "81a425f1a58941ac9c769e5838d28f10",
            "f74bd0e8aa6f4c1a87a1abc314e65346",
            "105dcb1b72f74dea99e7bcea28f4972f",
            "5f9863e4e7eb4e7fa7820218b564d66b",
            "bc4c6ab2744143ad991a67e7ac2306a6",
            "3c37834fe04140fc858617a1cbeecfb9",
            "87884b5a0e7243bba79de17aa065a938",
            "968de739d2294c66b4e53338404849d6",
            "28dbc2b6e3c4446eb32e9a4803dfe66a",
            "5c9e6b5d4d70496aa087ccf6bf9b75ba",
            "c157cc126d6f4aa6a6149a6b024bbb00",
            "00c7bb44be2747c6af32e378131c5c2b",
            "4b8a044e2dfd4622ac768bb34f73081c",
            "de0b1706dd8945508f14872417c6858e",
            "7b4d2e858e2649d7a1bd0147b049424a",
            "8f4209cec70348e19efee7427bc309dd",
            "5d73785c76a54117955db6da1d77fef0",
            "81b4d2f3662d4ab9acb31ddf80f772e6",
            "c68131f69e7b4bebae0330d50d961ab2",
            "51c4b2c891e14a8185b03ea6d6223349",
            "b4d92a623499436eacca9484970c1740"
          ]
        },
        "id": "WP6DELv31tnu",
        "outputId": "a363d9b6-f4f0-4b91-bc66-f527a014269e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting range_max to 55 based on the provided parameters.\n",
            "Found 154 unique queries out of 491 total queries.\n",
            "Found an average of 3.188 positives per query.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2827540ce35c47ff8d1e2eb3712b550e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c157cc126d6f4aa6a6149a6b024bbb00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Querying FAISS index: 100%|██████████| 1/1 [00:00<00:00, 45.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metric       Positive       Negative     Difference\n",
            "Count             491         24,550               \n",
            "Mean           0.4280         0.4167         0.0114\n",
            "Median         0.4312         0.4152         0.0053\n",
            "Std            0.1499         0.1238         0.1363\n",
            "Min            0.0165         0.1251        -0.5122\n",
            "25%            0.3265         0.3309        -0.0782\n",
            "50%            0.4312         0.4152         0.0053\n",
            "75%            0.5316         0.5089         0.0986\n",
            "Max            0.7839         0.8124         0.5326\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers.cross_encoder.evaluation import CrossEncoderRerankingEvaluator\n",
        "from sentence_transformers.cross_encoder import CrossEncoderTrainingArguments, CrossEncoderTrainer, losses\n",
        "from sentence_transformers.util import mine_hard_negatives\n",
        "\n",
        "eval_dataset = load_positive_train_ds(dev_df, evidence_df,dev_claims_embeddings, evidence_embeddings)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "embedding_model = SentenceTransformer(\"sentence-transformers/static-retrieval-mrl-en-v1\", device=device)\n",
        "hard_eval_dataset = mine_hard_negatives(\n",
        "    eval_dataset,\n",
        "    embedding_model,\n",
        "    corpus = train_dataset[\"answer\"],  # Use the full dataset as the corpus\n",
        "    num_negatives=50,  # How many negatives per question-answer pair\n",
        "    batch_size=4096,  # Use a batch size of 4096 for the embedding model\n",
        "    output_format=\"n-tuple\",  # The output format is (query, positive, negative1, negative2, ...) for the evaluator\n",
        "    include_positives=True,  # Key: Include the positive answer in the list of negatives\n",
        "    use_faiss=True,  # Using FAISS is recommended to keep memory usage low (pip install faiss-gpu or pip install faiss-cpu)\n",
        ")\n",
        "\n",
        "reranking_evaluator = CrossEncoderRerankingEvaluator(\n",
        "    samples=[\n",
        "        {\n",
        "            \"query\": sample[\"query\"],\n",
        "            \"positive\": [sample[\"answer\"]],\n",
        "            \"documents\": [sample[column_name] for column_name in hard_eval_dataset.column_names[2:]],\n",
        "        }\n",
        "        for sample in hard_eval_dataset\n",
        "    ],\n",
        "    batch_size=32,\n",
        "    name=\"gooaq-dev\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "RHB2BnZA1tnu",
        "outputId": "831ec840-91bf-4afb-da34-790f76c828ba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1548' max='1548' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1548/1548 06:39, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Gooaq-dev Map</th>\n",
              "      <th>Gooaq-dev Mrr@10</th>\n",
              "      <th>Gooaq-dev Ndcg@10</th>\n",
              "      <th>Gooaq-dev Base Map</th>\n",
              "      <th>Gooaq-dev Base Mrr@10</th>\n",
              "      <th>Gooaq-dev Base Ndcg@10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.427800</td>\n",
              "      <td>0.218383</td>\n",
              "      <td>0.320952</td>\n",
              "      <td>0.304256</td>\n",
              "      <td>0.393210</td>\n",
              "      <td>0.211680</td>\n",
              "      <td>0.200438</td>\n",
              "      <td>0.255458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.225100</td>\n",
              "      <td>0.163419</td>\n",
              "      <td>0.325189</td>\n",
              "      <td>0.309096</td>\n",
              "      <td>0.400726</td>\n",
              "      <td>0.211680</td>\n",
              "      <td>0.200438</td>\n",
              "      <td>0.255458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.185300</td>\n",
              "      <td>0.180082</td>\n",
              "      <td>0.326072</td>\n",
              "      <td>0.309773</td>\n",
              "      <td>0.401365</td>\n",
              "      <td>0.211680</td>\n",
              "      <td>0.200438</td>\n",
              "      <td>0.255458</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1548, training_loss=0.27716211139077673, metrics={'train_runtime': 399.5769, 'train_samples_per_second': 30.948, 'train_steps_per_second': 3.874, 'total_flos': 0.0, 'train_loss': 0.27716211139077673, 'epoch': 3.0})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "\n",
        "reranking_evaluator(cross_encoder)\n",
        "\n",
        "\n",
        "model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
        "short_model_name = model_name if \"/\" not in model_name else model_name.split(\"/\")[-1]\n",
        "run_name = f\"reranker-{short_model_name}-gooaq-cmnrl\"\n",
        "args = CrossEncoderTrainingArguments(\n",
        "    # Required parameter:\n",
        "    output_dir=f\"models/{run_name}\",\n",
        "    # Optional training parameters:\n",
        "    num_train_epochs= 3,\n",
        "    per_device_train_batch_size= 8,\n",
        "    per_device_eval_batch_size= 8,\n",
        "    learning_rate= 1e-5,\n",
        "    warmup_ratio=0.1,\n",
        "    fp16=False,  # Set to False if you get an error that your GPU can't run on FP16\n",
        "    bf16=True,  # Set to True if you have a GPU that supports BF16\n",
        "    # Optional tracking/debugging parameters:\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "\n",
        "    save_total_limit=2,\n",
        "    run_name=run_name,  # Will be used in W&B if `wandb` is installed\n",
        "    seed=12,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        "    greater_is_better=False,\n",
        "    weight_decay = 0.01,\n",
        ")\n",
        "loss = losses.MultipleNegativesRankingLoss(model=cross_encoder)\n",
        "\n",
        "trainer = CrossEncoderTrainer(\n",
        "    model=cross_encoder,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    loss=loss,\n",
        "    evaluator=reranking_evaluator,\n",
        "    eval_dataset=eval_dataset,\n",
        ")\n",
        "trainer.train()\n",
        "\n",
        "# cross_encoder.fit(\n",
        "\n",
        "#     train_dataloader=train_dataloader,\n",
        "#     # loss_fct=train_loss,\n",
        "#     epochs=20,\n",
        "#     output_path='./fine-tuned-cross-encoder',\n",
        "#     weight_decay=0.01\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sjCK9sR1tnu"
      },
      "source": [
        "Second retrieve for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLC-Av051tnv"
      },
      "outputs": [],
      "source": [
        "# train_retrieval = retrieve(evidence_embeddings, train_claims_embeddings, evidence_df , train_df, 150, 4, True, 2, cross_encoder, True)\n",
        "# save_retrieval(train_retrieval, 'train_retrieval.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogQVrLlI1tnv"
      },
      "outputs": [],
      "source": [
        "dev_retrieval = retrieve(evidence_embeddings, dev_claims_embeddings, evidence_df , dev_df, 150, 5, True, 0, cross_encoder, False)\n",
        "save_retrieval(dev_retrieval, 'dev_retrieval.json')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYT4esgGm3of"
      },
      "source": [
        "I will do a classficiation, we were thinking of using transformer model then LSTM, and compare them and use the one with the best performance.\n",
        "For transformer, in this fact checking task, I will first try with the multi encoder fusion because we have a lot of cluses in the evidence and want to combine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d2e6679f847048ca8f024adf84620806",
            "3061fc2607ed4478a4d1273bc5568aa3",
            "7729529e95aa46c899f5b90de91595ec",
            "08ee72f9764249a693b81228918228b7",
            "5786290649ca46efaee90ad5199e7791",
            "210c8fa7efb94683918fd5bb253e86e2",
            "9fa3f4aba5564d29b0afa7194dc61377",
            "52cc6c162df84f1ca5ee07be2e2d3adb",
            "39584891998244b3928ab0ebca16a60d",
            "916413930501492882af2e920a78adbb",
            "30faa1265fa3482ba751940d4e780290"
          ]
        },
        "id": "F1GleSsh1tnv",
        "outputId": "a216d3b8-4160-466f-804c-b094e37c25b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\"claim-2967\": {\"claim_text\": \"The contribution of waste heat to the global climate is 0.028 W/m2.\"}, \"claim-979\": {\"claim_text\": \"\\u201cWarm weather worsened the most recent five-year drought, which \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2e6679f847048ca8f024adf84620806",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress  0.0 %\n",
            "Progress  0.654 %\n",
            "Progress  1.307 %\n",
            "Progress  1.961 %\n",
            "Progress  2.614 %\n",
            "Progress  3.268 %\n",
            "Progress  3.922 %\n",
            "Progress  4.575 %\n",
            "Progress  5.229 %\n",
            "Progress  5.882 %\n",
            "Progress  6.536 %\n",
            "Progress  7.19 %\n",
            "Progress  7.843 %\n",
            "Progress  8.497 %\n",
            "Progress  9.15 %\n",
            "Progress  9.804 %\n",
            "Progress  10.458 %\n",
            "Progress  11.111 %\n",
            "Progress  11.765 %\n",
            "Progress  12.418 %\n",
            "Progress  13.072 %\n",
            "Progress  13.725 %\n",
            "Progress  14.379 %\n",
            "Progress  15.033 %\n",
            "Progress  15.686 %\n",
            "Progress  16.34 %\n",
            "Progress  16.993 %\n",
            "Progress  17.647 %\n",
            "Progress  18.301 %\n",
            "Progress  18.954 %\n",
            "Progress  19.608 %\n",
            "Progress  20.261 %\n",
            "Progress  20.915 %\n",
            "Progress  21.569 %\n",
            "Progress  22.222 %\n",
            "Progress  22.876 %\n",
            "Progress  23.529 %\n",
            "Progress  24.183 %\n",
            "Progress  24.837 %\n",
            "Progress  25.49 %\n",
            "Progress  26.144 %\n",
            "Progress  26.797 %\n",
            "Progress  27.451 %\n",
            "Progress  28.105 %\n",
            "Progress  28.758 %\n",
            "Progress  29.412 %\n",
            "Progress  30.065 %\n",
            "Progress  30.719 %\n",
            "Progress  31.373 %\n",
            "Progress  32.026 %\n",
            "Progress  32.68 %\n",
            "Progress  33.333 %\n",
            "Progress  33.987 %\n",
            "Progress  34.641 %\n",
            "Progress  35.294 %\n",
            "Progress  35.948 %\n",
            "Progress  36.601 %\n",
            "Progress  37.255 %\n",
            "Progress  37.908 %\n",
            "Progress  38.562 %\n",
            "Progress  39.216 %\n",
            "Progress  39.869 %\n",
            "Progress  40.523 %\n",
            "Progress  41.176 %\n",
            "Progress  41.83 %\n",
            "Progress  42.484 %\n",
            "Progress  43.137 %\n",
            "Progress  43.791 %\n",
            "Progress  44.444 %\n",
            "Progress  45.098 %\n",
            "Progress  45.752 %\n",
            "Progress  46.405 %\n",
            "Progress  47.059 %\n",
            "Progress  47.712 %\n",
            "Progress  48.366 %\n",
            "Progress  49.02 %\n",
            "Progress  49.673 %\n",
            "Progress  50.327 %\n",
            "Progress  50.98 %\n",
            "Progress  51.634 %\n",
            "Progress  52.288 %\n",
            "Progress  52.941 %\n",
            "Progress  53.595 %\n",
            "Progress  54.248 %\n",
            "Progress  54.902 %\n",
            "Progress  55.556 %\n",
            "Progress  56.209 %\n",
            "Progress  56.863 %\n",
            "Progress  57.516 %\n",
            "Progress  58.17 %\n",
            "Progress  58.824 %\n",
            "Progress  59.477 %\n",
            "Progress  60.131 %\n",
            "Progress  60.784 %\n",
            "Progress  61.438 %\n",
            "Progress  62.092 %\n",
            "Progress  62.745 %\n",
            "Progress  63.399 %\n",
            "Progress  64.052 %\n",
            "Progress  64.706 %\n",
            "Progress  65.359 %\n"
          ]
        }
      ],
      "source": [
        "with open('test-claims-unlabelled.json','r') as f:\n",
        "    data = f.read()\n",
        "print(data[:200])\n",
        "\n",
        "test_df = json.loads(data)\n",
        "flat_list = []\n",
        "for key in test_df:\n",
        "    flat_list.append({\"ID\": key, \"claim_text\": test_df[key]['claim_text']})\n",
        "tst_df = pd.DataFrame(flat_list)\n",
        "tst_claims_embeddings = model.encode(tst_df['claim_text'], batch_size=64, show_progress_bar=True)\n",
        "retrieval = retrieve(evidence_embeddings, tst_claims_embeddings, evidence_df , tst_df, 150, 5, False, 0, cross_encoder, False)\n",
        "save_retrieval(retrieval, 'test-output.json')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyfsBa38m3of"
      },
      "outputs": [],
      "source": [
        "with open('test-output.json', 'r') as f:\n",
        "    test_output = json.load(f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKh7TFBmm3of"
      },
      "source": [
        "I am going to initialise a transformer model and tokensizer for the evidence classification task.\n",
        "My plan is to use fastest training times and speed as this is done from gooogle collab and our retrival already takes a lot of time which almost is 6 hours to train in colab unfortunately. We have enough disk space but I want to keep the training simple and most generic as possible.\n",
        "There were few options, but we will go with distilbert-base-uncased, which is a smaller version of BERT.\n",
        "\n",
        "Decisions based on cased and uncased is uncased because itt is faster and no need to worry about capital named entities.\n",
        "{SUPPORTS, REFUTES, NOT_ENOUGH_INFO, DISPUTED} There are 4 classes in the evidence classification task.\n",
        "\n",
        "I also want to keep the label order and everything simple as possible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krkaTSSfm3of"
      },
      "outputs": [],
      "source": [
        "# import that wasn't done in the beginning\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# model choice and label list initialization\n",
        "classifer_model = \"distilbert-base-uncased\"\n",
        "label_list=[\"SUPPORTS\", \"REFUTES\", \"NOT_ENOUGH_INFO\", \"DISPUTED\"]\n",
        "num_labels = len(label_list)\n",
        "label_map = {label: i for i, label in enumerate(label_list)}\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "\n",
        "print(\"Label Map: \", label_map)\n",
        "print(\"ID to Label Map: \", id2label)\n",
        "\n",
        "#load the model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(classifer_model)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(classifer_model, num_labels=num_labels, id2label=id2label, label2id=label_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJUcQIW8m3og"
      },
      "source": [
        "For preparing training data from claims for the ground truth evidence, I will be using  one training instance per evidence.\n",
        "E.g.\n",
        "1. (claim_tex [SEP] evidence_text_1, \"SUPPORTS\")\n",
        "2. (claim_text [SEP] evidence_text_2, \"SUPPORTS\")\n",
        "3. (claim_text [SEP] evidence_text_3, \"REFUTES\")\n",
        "4. (claim_text [SEP] evidence_text_4, \"NOT_ENOUGH_INFO\")\n",
        "5. (claim_text [SEP] evidence_text_5, \"DISPUTED\")\n",
        "\n",
        "Kind of ways, because this is the best way to train data for the model.\n",
        "\n",
        "Some options we considered were: only using one of the randomly selected evidence or first evidence.\n",
        "Or put all evidenece in one instance.\n",
        "\n",
        "We will also use PyTorch for the training to do it manually instead of huggingface trainer.\n",
        "\n",
        "Hyperparameters for the training:\n",
        "- learning_rate = ADAMW(1e-5) Optimizer\n",
        "- batch_size = 16\n",
        "- epochs = 10\n",
        "\n",
        "We will use dev-claims for validation and test-claims for testing.\n",
        "\n",
        "We will try to look for f score and accuracy for the evaluation.\n",
        "\n",
        "For the ones that has label but no listed evidence, we will create a special input format like\n",
        "(claim_text [SEP], \"NOT_ENOUGH_INFO\") since we are not allowed to modify the dataset or can't skip it written in the project description.\n",
        "claims labllee\n",
        "\n",
        "Also later changed to tokenizers real separator (tokenizer.sep_token) in order to learn the model better.\n",
        "\n",
        "Also I added a checkpoint to train fixed 10 epochs and save the best model by tracking the best accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgzsadBUm3og"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# custom pytorch dataset class\n",
        "class ClaimEvidenceDataset(Dataset):\n",
        "    def __init__(self, data_list, tokenizer, max_len=128):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.texts = [item['text'] for item in data_list]\n",
        "        self.labels = [item['label_id'] for item in data_list]\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        encoding = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids':      encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'labels':         torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# function to match the evidence with the claim and prepare the dataset using separator\n",
        "def prepare_data(df, evidence_df, label_map):\n",
        "    items = []\n",
        "    for _, row in df.iterrows():\n",
        "        claim_text = row['claim_text']\n",
        "        for evid_id in row.get('evidences', []):\n",
        "            evid_row = evidence_df[evidence_df['ID'] == evid_id]\n",
        "            if evid_row.empty:\n",
        "                continue\n",
        "            # [SEP] token is used to separate claim and evidence\n",
        "            text = f\"{claim_text} {tokenizer.sep_token} {evid_row['value'].iloc[0]}\"\n",
        "            label = label_map[row['claim_label']]\n",
        "            items.append({'text': text, 'label_id': label})\n",
        "    return items\n",
        "\n",
        "# build datasets and dataloaders\n",
        "train_items = prepare_data(train_df, evidence_df, label_map)\n",
        "dev_items   = prepare_data(dev_df,   evidence_df, label_map)\n",
        "\n",
        "# print to debug it is working simple\n",
        "print(\"Done preparing daata: \", len(train_items), \" train items and \", len(dev_items), \" dev items\")\n",
        "\n",
        "train_dataset = ClaimEvidenceDataset(train_items, tokenizer)\n",
        "dev_dataset   = ClaimEvidenceDataset(dev_items,   tokenizer)\n",
        "\n",
        "# print to debug the claimevidence dataset is working\n",
        "print(\"Train Dataset: \", train_dataset[0])\n",
        "print(\"Dev Dataset: \", dev_dataset[0])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "dev_loader   = DataLoader(dev_dataset,   batch_size=16)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkEmMytjE0YT"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, train_loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
        "    for batch in progress_bar:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids      = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels         = batch[\"labels\"].to(device)\n",
        "        outputs = model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            labels=labels\n",
        "        )\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        progress_bar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def evaluate_model(model, dev_loader, device, label_names):\n",
        "    model.eval()\n",
        "    preds, trues = [], []\n",
        "    progress_bar = tqdm(dev_loader, desc=\"Evaluating\")\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            input_ids      = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels         = batch[\"labels\"].to(device)\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "            logits = outputs.logits\n",
        "            preds.extend(torch.argmax(logits, dim=1).cpu().tolist())\n",
        "            trues.extend(labels.cpu().tolist())\n",
        "    acc = accuracy_score(trues, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(trues, preds, average=\"weighted\")\n",
        "    print(f\"Dev acc: {acc:.4f}, F1: {f1:.4f}\")\n",
        "    print(classification_report(trues, preds, target_names=label_names))\n",
        "    return f1\n",
        "\n",
        "def train_and_evaluate(model, train_loader, dev_loader, optimizer, device, epochs, label_names, save_path=\"model_best.pth\"):\n",
        "    best_f1 = 0\n",
        "    best_state = None\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
        "        print(f\"Epoch {epoch} Train loss: {train_loss:.4f}\")\n",
        "        f1 = evaluate_model(model, dev_loader, device, label_names)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_state = model.state_dict().copy()\n",
        "            print(f\"New best F1: {best_f1:.4f}\")\n",
        "    if best_state:\n",
        "        model.load_state_dict(best_state)\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Best model saved to {save_path} with F1: {best_f1:.4f}\")\n",
        "\n",
        "\n",
        "# Set training parameters\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-5\n",
        "\n",
        "# move the model to the device for gpu\n",
        "model.to(device)\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
        "\n",
        "# Print training info\n",
        "print(f\"Starting training on {device}\")\n",
        "print(f\"Number of training examples: {len(train_dataset)}\")\n",
        "print(f\"Number of validation examples: {len(dev_dataset)}\")\n",
        "print(f\"Number of epochs: {num_epochs}\")\n",
        "\n",
        "# Train and evaluate model\n",
        "train_and_evaluate(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    dev_loader=dev_loader,\n",
        "    optimizer=optimizer,\n",
        "    device=device,\n",
        "    epochs=num_epochs,\n",
        "    label_names=label_list,\n",
        "    save_path=\"claim_evidence_classifier.pth\"\n",
        ")\n",
        "\n",
        "# Load the best model for further use\n",
        "model.load_state_dict(torch.load(\"claim_evidence_classifier.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u7NA2Ntm3og"
      },
      "source": [
        "Now I am going to load the best model state to store in state_dict to a file\n",
        "\n",
        "Also I will now need to prepare and batch the test data for prediction and for that I will use pytorch dataset and dataloader for convenience consistency and speed as google collab is slow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GItqoKyNm3og"
      },
      "outputs": [],
      "source": [
        "# evidence_df\n",
        "# dev_df\n",
        "# train_df\n",
        "# tst_df\n",
        "# test_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wy6nROaGm3oh"
      },
      "outputs": [],
      "source": [
        "# function to prepare test data\n",
        "def prepare_test_data(claim_text, evidences, evidence_df):\n",
        "    items = []\n",
        "    for evid_id in evidences:\n",
        "        evid_row = evidence_df[evidence_df['ID'] == evid_id]\n",
        "        if evid_row.empty:\n",
        "            continue\n",
        "        text = f\"{claim_text} {tokenizer.sep_token} {evid_row['value'].iloc[0]}\"\n",
        "        items.append({'text': text})\n",
        "    return items\n",
        "\n",
        "# function to predict labels\n",
        "def predict_claim_label(model, items, tokenizer, device):\n",
        "    model.eval()\n",
        "\n",
        "    # If no evidence, return NOT_ENOUGH_INFO\n",
        "    if not items:\n",
        "        return \"NOT_ENOUGH_INFO\"\n",
        "\n",
        "    # Create a dataset and dataloader for the items\n",
        "    class PredictionDataset(Dataset):\n",
        "        def __init__(self, items, tokenizer, max_len=128):\n",
        "            self.tokenizer = tokenizer\n",
        "            self.texts = [item['text'] for item in items]\n",
        "            self.max_len = max_len\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.texts)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            encoding = self.tokenizer(\n",
        "                self.texts[idx],\n",
        "                add_special_tokens=True,\n",
        "                max_length=self.max_len,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            return {\n",
        "                'input_ids': encoding['input_ids'].squeeze(0),\n",
        "                'attention_mask': encoding['attention_mask'].squeeze(0)\n",
        "            }\n",
        "\n",
        "    dataset = PredictionDataset(items, tokenizer)\n",
        "    dataloader = DataLoader(dataset, batch_size=8)\n",
        "\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1).cpu().tolist()\n",
        "            predictions.extend(preds)\n",
        "\n",
        "    # count occurrences of each label\n",
        "    counts = {}\n",
        "    for pred in predictions:\n",
        "        label = id2label[pred]\n",
        "        counts[label] = counts.get(label, 0) + 1\n",
        "\n",
        "    # return the most common label, or if tie, prioritize in order: SUPPORTS, REFUTES, DISPUTED, NOT_ENOUGH_INFO\n",
        "    if not counts:\n",
        "        return \"NOT_ENOUGH_INFO\"\n",
        "\n",
        "    max_count = max(counts.values())\n",
        "    max_labels = [label for label, count in counts.items() if count == max_count]\n",
        "\n",
        "    priority_order = [\"SUPPORTS\", \"REFUTES\", \"DISPUTED\", \"NOT_ENOUGH_INFO\"]\n",
        "    for label in priority_order:\n",
        "        if label in max_labels:\n",
        "            return label\n",
        "\n",
        "    return max_labels[0]  # Fallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load the dev output\n",
        "with open('dev_retrieval.json', 'r') as f:\n",
        "    dev_output = json.load(f)\n",
        "\n",
        "# predict labels for dev set\n",
        "print (\"Predicting labels for dev set...\")\n",
        "for claim_id, claim_data in dev_output.items():\n",
        "    claim_text = claim_data['claim_text']\n",
        "    evidences = claim_data['evidences']\n",
        "\n",
        "    # prepare data for this claim\n",
        "    items = prepare_test_data(claim_text, evidences, evidence_df)\n",
        "\n",
        "    # get prediction\n",
        "    predicted_label = predict_claim_label(model, items, tokenizer, device)\n",
        "\n",
        "    # update the label in the output\n",
        "    dev_output[claim_id]['predicted_label'] = predicted_label\n",
        "\n",
        "# save the updated dev output\n",
        "with open('dev_output_with_labels.json', 'w') as f:\n",
        "    json.dump(dev_output, f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsFV9tG-E0YU"
      },
      "outputs": [],
      "source": [
        "# load the test output\n",
        "with open('test-output.json', 'r') as f:\n",
        "    test_output = json.load(f)\n",
        "\n",
        "# predict labels for each claim\n",
        "print(\"Predicting labels for test claims...\")\n",
        "for claim_id, claim_data in tqdm(test_output.items()):\n",
        "    claim_text = claim_data['claim_text']\n",
        "    evidences = claim_data['evidences']\n",
        "\n",
        "    # prepare data for this claim\n",
        "    items = prepare_test_data(claim_text, evidences, evidence_df)\n",
        "\n",
        "    # get prediction\n",
        "    predicted_label = predict_claim_label(model, items, tokenizer, device)\n",
        "\n",
        "    # update the label in the output\n",
        "    test_output[claim_id]['claim_label'] = predicted_label\n",
        "\n",
        "# save the updated test output\n",
        "with open('test-output.json', 'w') as f:\n",
        "    json.dump(test_output, f, indent=2)\n",
        "\n",
        "print(\"Updated test-output.json with predicted labels\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3719  100  3719    0     0  12022      0 --:--:-- --:--:-- --:--:-- 12035\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'json' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Write out your dev predictions in the correct format\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdev_output_with_labels.json\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mjson\u001b[49m\u001b[38;5;241m.\u001b[39mdump(dev_predictions, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run the evaluation\u001b[39;00m\n\u001b[1;32m      9\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython eval.py --predictions dev_output_with_labels.json --groundtruth dev-claims.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'json' is not defined"
          ]
        }
      ],
      "source": [
        "# Download the evaluation script into the notebook\n",
        "!curl -o eval.py https://raw.githubusercontent.com/drcarenhan/COMP90042_2025/main/eval.py\n",
        "\n",
        "# Write out your dev predictions in the correct format\n",
        "with open('dev_output_with_labels.json','w') as f:\n",
        "    json.dump(dev_predictions, f, indent=2)\n",
        "\n",
        "# Run the evaluation\n",
        "!python eval.py --predictions dev_output_with_labels.json --groundtruth dev-claims.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00c7bb44be2747c6af32e378131c5c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f4209cec70348e19efee7427bc309dd",
            "placeholder": "​",
            "style": "IPY_MODEL_5d73785c76a54117955db6da1d77fef0",
            "value": "Batches: 100%"
          }
        },
        "080e9631ab6e4af4812b00b33e514a73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "087ee78e4ed24bc4b6d1580cd62afc35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8d985dcf88045ad89b879e8464dea64",
              "IPY_MODEL_e7d5fdfbb44f42f3a911d38566cce564",
              "IPY_MODEL_a78dfc05f8804769800944f737043be8"
            ],
            "layout": "IPY_MODEL_dd44a5a86c064e3095eba251ef7cb407"
          }
        },
        "08ee72f9764249a693b81228918228b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_916413930501492882af2e920a78adbb",
            "placeholder": "​",
            "style": "IPY_MODEL_30faa1265fa3482ba751940d4e780290",
            "value": " 3/3 [00:00&lt;00:00, 15.55it/s]"
          }
        },
        "0ae1257979604bb69d292bc3334fd7df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86c58567b73f4d21b07bd867f1a74a95",
            "max": 18888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_361a897e3ee843bf880a9a96075be79c",
            "value": 18888
          }
        },
        "0c09a86b14ad45418907647f1eae9b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "105dcb1b72f74dea99e7bcea28f4972f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_28dbc2b6e3c4446eb32e9a4803dfe66a",
            "placeholder": "​",
            "style": "IPY_MODEL_5c9e6b5d4d70496aa087ccf6bf9b75ba",
            "value": " 1/1 [00:00&lt;00:00,  2.47it/s]"
          }
        },
        "13a1ee388bf643ed8204c2c3b0466246": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d91ef6c522c4845bc21e2fd2a0c5df3",
              "IPY_MODEL_0ae1257979604bb69d292bc3334fd7df",
              "IPY_MODEL_315e3f11482c47deb9a4288a1998305f"
            ],
            "layout": "IPY_MODEL_4f45b82f78094b40a393fe063095ae64"
          }
        },
        "210c8fa7efb94683918fd5bb253e86e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23aa8d93e507418eb7600766bf0130ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2827540ce35c47ff8d1e2eb3712b550e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_81a425f1a58941ac9c769e5838d28f10",
              "IPY_MODEL_f74bd0e8aa6f4c1a87a1abc314e65346",
              "IPY_MODEL_105dcb1b72f74dea99e7bcea28f4972f"
            ],
            "layout": "IPY_MODEL_5f9863e4e7eb4e7fa7820218b564d66b"
          }
        },
        "28dbc2b6e3c4446eb32e9a4803dfe66a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e23e1bfe71043bf9b9b5838a79c6b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3061fc2607ed4478a4d1273bc5568aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_210c8fa7efb94683918fd5bb253e86e2",
            "placeholder": "​",
            "style": "IPY_MODEL_9fa3f4aba5564d29b0afa7194dc61377",
            "value": "Batches: 100%"
          }
        },
        "30faa1265fa3482ba751940d4e780290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "315e3f11482c47deb9a4288a1998305f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65949cecb87b49528da679d87bd263ea",
            "placeholder": "​",
            "style": "IPY_MODEL_df8c4abec5a44cdd8b994948c59769c5",
            "value": " 18888/18888 [09:11&lt;00:00, 95.47it/s]"
          }
        },
        "361a897e3ee843bf880a9a96075be79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "369bb264d861472686414d13b6d55fe2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39584891998244b3928ab0ebca16a60d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39fc652c065c41eb881000a82cdba552": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_885e10fe23b34691bd5de4e98d5aae8a",
            "placeholder": "​",
            "style": "IPY_MODEL_db323d362eb246e5a6049af3eea628eb",
            "value": " 20/20 [00:00&lt;00:00, 35.88it/s]"
          }
        },
        "3c37834fe04140fc858617a1cbeecfb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3efa77c5f3364325a7a86a3d0043dd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40264050651b4732bcbd198e77e90139": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b8a044e2dfd4622ac768bb34f73081c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81b4d2f3662d4ab9acb31ddf80f772e6",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c68131f69e7b4bebae0330d50d961ab2",
            "value": 1
          }
        },
        "4f45b82f78094b40a393fe063095ae64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c4b2c891e14a8185b03ea6d6223349": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52cc6c162df84f1ca5ee07be2e2d3adb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5786290649ca46efaee90ad5199e7791": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9d88e0ad164283bb6c2f426a9567a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9e6b5d4d70496aa087ccf6bf9b75ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d73785c76a54117955db6da1d77fef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f9863e4e7eb4e7fa7820218b564d66b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65949cecb87b49528da679d87bd263ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "672e1e25795d4222a01ef2c06efe982d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "68ef3582c85144ca901fe0721f771681": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6baee30c35834de6a41595b48ca650df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dfa3cba90f642a582e737ba33fd6b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73b44ac385674c04a8b753ad5601689c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7729529e95aa46c899f5b90de91595ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52cc6c162df84f1ca5ee07be2e2d3adb",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_39584891998244b3928ab0ebca16a60d",
            "value": 3
          }
        },
        "7b4d2e858e2649d7a1bd0147b049424a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81a425f1a58941ac9c769e5838d28f10": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc4c6ab2744143ad991a67e7ac2306a6",
            "placeholder": "​",
            "style": "IPY_MODEL_3c37834fe04140fc858617a1cbeecfb9",
            "value": "Batches: 100%"
          }
        },
        "81b4d2f3662d4ab9acb31ddf80f772e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86c58567b73f4d21b07bd867f1a74a95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87884b5a0e7243bba79de17aa065a938": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "885e10fe23b34691bd5de4e98d5aae8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f4209cec70348e19efee7427bc309dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9109e87ea86a477db3c6a077325ba5f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "916413930501492882af2e920a78adbb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9349372512dd4bfd84e5a8673a5bf38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dfa3cba90f642a582e737ba33fd6b0c",
            "placeholder": "​",
            "style": "IPY_MODEL_955aa777810b44d6a372a27053d2a842",
            "value": " 3/3 [00:00&lt;00:00, 16.88it/s]"
          }
        },
        "955aa777810b44d6a372a27053d2a842": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "968de739d2294c66b4e53338404849d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d91ef6c522c4845bc21e2fd2a0c5df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b44ac385674c04a8b753ad5601689c",
            "placeholder": "​",
            "style": "IPY_MODEL_23aa8d93e507418eb7600766bf0130ef",
            "value": "Batches: 100%"
          }
        },
        "9fa3f4aba5564d29b0afa7194dc61377": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a584fdcdf1864079a52ee22b4937c67c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a78dfc05f8804769800944f737043be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_369bb264d861472686414d13b6d55fe2",
            "placeholder": "​",
            "style": "IPY_MODEL_0c09a86b14ad45418907647f1eae9b85",
            "value": " 1/1 [00:00&lt;00:00,  7.34example/s]"
          }
        },
        "a8d985dcf88045ad89b879e8464dea64": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f07f0f107da84d07bc344b1429bacc46",
            "placeholder": "​",
            "style": "IPY_MODEL_cb98c824d58e4cacbad2f178e8ad6047",
            "value": "Computing widget examples: 100%"
          }
        },
        "b4a57a56ca22406781400f42b4aca6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9189a6818b744679c5f6dfe2cdfa6eb",
              "IPY_MODEL_bb6d9ba5d27947909d7e467e9a7617a9",
              "IPY_MODEL_39fc652c065c41eb881000a82cdba552"
            ],
            "layout": "IPY_MODEL_a584fdcdf1864079a52ee22b4937c67c"
          }
        },
        "b4d92a623499436eacca9484970c1740": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b655a47931314ea2bb9e7bbf001c8a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6baee30c35834de6a41595b48ca650df",
            "placeholder": "​",
            "style": "IPY_MODEL_dc07fc4b3ff34d1fba0dfa050faa1dab",
            "value": "Batches: 100%"
          }
        },
        "bb6d9ba5d27947909d7e467e9a7617a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c9d88e0ad164283bb6c2f426a9567a0",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_672e1e25795d4222a01ef2c06efe982d",
            "value": 20
          }
        },
        "bc4c6ab2744143ad991a67e7ac2306a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0e3508ba161497f9a625f3408c8c001": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c157cc126d6f4aa6a6149a6b024bbb00": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00c7bb44be2747c6af32e378131c5c2b",
              "IPY_MODEL_4b8a044e2dfd4622ac768bb34f73081c",
              "IPY_MODEL_de0b1706dd8945508f14872417c6858e"
            ],
            "layout": "IPY_MODEL_7b4d2e858e2649d7a1bd0147b049424a"
          }
        },
        "c68131f69e7b4bebae0330d50d961ab2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb98c824d58e4cacbad2f178e8ad6047": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0dde043112745159cd59c4fe5557b66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9109e87ea86a477db3c6a077325ba5f8",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68ef3582c85144ca901fe0721f771681",
            "value": 3
          }
        },
        "d2e6679f847048ca8f024adf84620806": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3061fc2607ed4478a4d1273bc5568aa3",
              "IPY_MODEL_7729529e95aa46c899f5b90de91595ec",
              "IPY_MODEL_08ee72f9764249a693b81228918228b7"
            ],
            "layout": "IPY_MODEL_5786290649ca46efaee90ad5199e7791"
          }
        },
        "d9189a6818b744679c5f6dfe2cdfa6eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40264050651b4732bcbd198e77e90139",
            "placeholder": "​",
            "style": "IPY_MODEL_2e23e1bfe71043bf9b9b5838a79c6b86",
            "value": "Batches: 100%"
          }
        },
        "db323d362eb246e5a6049af3eea628eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc07fc4b3ff34d1fba0dfa050faa1dab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd44a5a86c064e3095eba251ef7cb407": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "de0b1706dd8945508f14872417c6858e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c4b2c891e14a8185b03ea6d6223349",
            "placeholder": "​",
            "style": "IPY_MODEL_b4d92a623499436eacca9484970c1740",
            "value": " 1/1 [00:00&lt;00:00, 28.22it/s]"
          }
        },
        "df8c4abec5a44cdd8b994948c59769c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7d5fdfbb44f42f3a911d38566cce564": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0e3508ba161497f9a625f3408c8c001",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3efa77c5f3364325a7a86a3d0043dd74",
            "value": 1
          }
        },
        "f07f0f107da84d07bc344b1429bacc46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f74bd0e8aa6f4c1a87a1abc314e65346": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87884b5a0e7243bba79de17aa065a938",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_968de739d2294c66b4e53338404849d6",
            "value": 1
          }
        },
        "fb1918ee12f144aaa7b9ec549e044d3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b655a47931314ea2bb9e7bbf001c8a65",
              "IPY_MODEL_d0dde043112745159cd59c4fe5557b66",
              "IPY_MODEL_9349372512dd4bfd84e5a8673a5bf38f"
            ],
            "layout": "IPY_MODEL_080e9631ab6e4af4812b00b33e514a73"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
